{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном ноутбуке вам предстоит реализовать алгоритм Виолы-Джонса для детекции лиц.\n",
    "\n",
    "Полное описание алгоритма находится в статье https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf\n",
    "\n",
    "Алгоритм является довольно ресурсоемким, поэтому если будет не хватать памяти, то попробуйте уменьшить количество изображений в наборе. На тысяче изображений обоих классов все еще можно получить неплохие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Считаем данные\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import abc\n",
    "\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(starting_dir, nsamples=None):\n",
    "    images = []\n",
    "    stop = False\n",
    "    extensions = [\"pgm\", \"jpeg\", \"jpg\", \"png\"]\n",
    "    pbar = tqdm(os.walk(starting_dir), desc=f'loading from {starting_dir}, {len(images)} found')\n",
    "    for dir_name, _, filenames in pbar:\n",
    "        for filename in filenames:\n",
    "            extension = os.path.splitext(filename)[1][1:]\n",
    "            if extension in extensions:\n",
    "                image = io.imread(os.path.join(dir_name, filename))\n",
    "                images.append(image)\n",
    "                pbar.set_description(f'loading from {starting_dir}, {len(images)} found')\n",
    "                stop = nsamples and len(images) >= nsamples\n",
    "            if stop:\n",
    "                break\n",
    "        if stop:\n",
    "            pbar.set_description(f'{starting_dir} done, {len(images)} found')\n",
    "            break\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "loading from data/positives, 0 found: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf44aa3c1d374ba1ad13b4855fff6ddc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "loading from data/negatives, 0 found: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e9b5662ffac4ab4a496577c004ad423"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positives = get_all_images('data/positives')\n",
    "n_positives = len(positives)\n",
    "negatives = get_all_images('data/negatives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зафиксируем размер окна, на котором будет работать классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_canonical_size = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычтем из изображения среднее и поделим на стандартное отклонение\n",
    "def normalize_images(images):\n",
    "    result = []\n",
    "    for image in tqdm(images, desc='normalizing'):\n",
    "        mean, std = image.mean(), image.std()\n",
    "        result.append((image - mean) / std)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг изображений с лицами\n",
    "\n",
    "* Нормируем яркость, чтобы не учитывать освещенность\n",
    "* Преобразуем к 24 * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_positives(images, size):\n",
    "    result = []\n",
    "    normilized_images = normalize_images(images)\n",
    "    for normilized_image in tqdm(normilized_images, desc='resizing'):\n",
    "        resized_image = resize(normilized_image, (size, size), mode='constant').astype(np.float32)\n",
    "        result.append(resized_image)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "normalizing:   0%|          | 0/3206 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c0dcb1521d74d77a027918665c56dbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "resizing:   0%|          | 0/3206 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68c0b0071bd54080999992e8043a4aa8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positives_prepared = prepare_positives(positives, image_canonical_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг изображений без лиц\n",
    "\n",
    "* Вырежем случайные квадраты из негативных изображений\n",
    "* Нормируем яркость\n",
    "* Преобразуем к 24 * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "def prepare_negatives(images, sample_size, size):\n",
    "    norm_images = normalize_images(images)\n",
    "    crops = []\n",
    "    for _ in tqdm(range(0, sample_size), desc='cropping'):\n",
    "        image_ind = randint(0, len(norm_images) - 1)\n",
    "        image = norm_images[image_ind]\n",
    "        w, h = image.shape\n",
    "        max_r = min(w, h)\n",
    "        r = randint(size, max_r)\n",
    "        x, y = randint(0, w - max_r), randint(0, h - max_r)\n",
    "        crop = image[x: x + r, y: y + r]\n",
    "        crop = resize(crop, (size, size), mode='constant').astype(np.float32)\n",
    "        crops.append(crop)\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "normalizing:   0%|          | 0/3019 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b56be41c9340475fa0066ff7fb253081"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "cropping:   0%|          | 0/3019 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7941f7c01e594cfbb397b138f5775a8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Возьмем столько же негативных изображений, сколько позитивных\n",
    "n_negatives = len(negatives)\n",
    "negatives_prepared = prepare_negatives(negatives, n_negatives, image_canonical_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверим, что данные имеют правильный формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_has_correct_format(image, shape=(image_canonical_size, image_canonical_size)):\n",
    "    return image.shape == shape\n",
    "\n",
    "\n",
    "assert (len(positives_prepared) == n_positives)\n",
    "assert (all(\n",
    "    [image_has_correct_format(im) for im in positives_prepared]\n",
    "))\n",
    "\n",
    "assert (len(negatives_prepared) == n_negatives)\n",
    "assert (all(\n",
    "    [image_has_correct_format(im) for im in negatives_prepared]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интегральное изображение\n",
    "\n",
    "Чтобы эффективно вычислять признаки Хаара нам понадобится специальное представление изображения под названием Интегральное изображение.\n",
    "\n",
    "Интегральное изображение I -- это матрица, совпадающая по размерам с исходным изображением, в которой I(x, y) = сумме всех интенсивностей пикселей левее и выше (x, y) (включая [x, y]). Такое представление позволяет очень быстро находить сумму интенсивностей пикселей в любом подпрямоугольнике изображения (что нужно для вычисления признаков Хаара).\n",
    "\n",
    "Принцип работы проще всего понять графически:\n",
    "\n",
    "<img src=\"img/integral.png\",width=300,height=300>\n",
    "\n",
    "Чтобы найти площадь серого прямоугольника мы можем использовать только прямоугольники, начинающиеся из (0,0). Именно эти суммы мы и храним в интегральном изображении.\n",
    "\n",
    "Несложно видеть, что \n",
    "\n",
    "S = C - B - D + A\n",
    "\n",
    "Вам необходимо реализовать интегральное изображение самостоятельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class IntegralImage:\n",
    "    def __init__(self, image):\n",
    "        # hint: воспользуйтесь numpy.cumsum два раза, чтобы получить двумерную кумулятивную сумму\n",
    "        self.integral_image = np.cumsum(np.cumsum(image, axis=1), axis=0)\n",
    "\n",
    "\n",
    "    def sum(self, x1, y1, x2, y2):\n",
    "        '''\n",
    "        Сумма подмассива\n",
    "        \n",
    "        На входе:\n",
    "            x1, y1 -- координаты левого нижнего угла прямоугольника запроса\n",
    "            x2, y2 -- координаты верхнего правого угла прямоугольника запроса\n",
    "            \n",
    "        На выходе:\n",
    "            Сумма подмассива [x1..x2, y1..y2]\n",
    "        '''\n",
    "        return sum_IntegralImage(self.integral_image, x1, y1, x2, y2)\n",
    "        # assert (x1 <= x2)\n",
    "        # assert (y1 <= y2)\n",
    "        # b1 = self.integral_image[x1 - 1, y1 - 1] if x1 and y1 else 0\n",
    "        # b2 = self.integral_image[x2, y1 - 1] if y1 else 0\n",
    "        # b3 = self.integral_image[x1 - 1, y2] if x1 else 0\n",
    "        # b4 = self.integral_image[x2, y2]\n",
    "        # return b4 - b2 - b3 + b1\n",
    "\n",
    "@numba.jit()\n",
    "def sum_IntegralImage(integral_image, x1, y1, x2, y2):\n",
    "    assert (x1 <= x2)\n",
    "    assert (y1 <= y2)\n",
    "    b1 = integral_image[x1 - 1, y1 - 1] if x1 and y1 else 0\n",
    "    b2 = integral_image[x2, y1 - 1] if y1 else 0\n",
    "    b3 = integral_image[x1 - 1, y2] if x1 else 0\n",
    "    b4 = integral_image[x2, y2]\n",
    "    return b4 - b2 - b3 + b1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Протестируем"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "test_image = np.asarray([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "test_integral_image = IntegralImage(test_image)\n",
    "assert (test_integral_image.sum(0, 0, 2, 2) == sum(range(0, 10)))\n",
    "assert (test_integral_image.sum(0, 0, 0, 0) == 1)\n",
    "assert (test_integral_image.sum(0, 0, 2, 0) == 12)\n",
    "assert (test_integral_image.sum(0, 1, 1, 2) == 16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовим интегральные изображения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "integral_positives = [IntegralImage(im) for im in positives_prepared]\n",
    "integral_negatives = [IntegralImage(im) for im in negatives_prepared]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Признаки Хаара\n",
    "\n",
    "В оригинальной работе использовались признаки следующего вида:\n",
    "\n",
    "<img src=\"haar_features_1.jpg\">\n",
    "\n",
    "Значение признака = s1 - s2, где s1 = сумма интенсивностей в светлой области, s2 = сумма интенсивностей в темной области\n",
    "Не обязательно использовать все эти признаки, но рекомендуется попробовать. Ниже необходимо реализовать их.\n",
    "\n",
    "Признак задается координатами левого верхнего угла, шириной и высотой окна. Считаем, что ось x идет сверху вниз, а ось y -- справа-налево. w -- это размер окна по оси x, h -- по оси y."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Общий интерфейс для всех классов признаков\n",
    "\n",
    "class HaarFeature(metaclass=abc.ABCMeta):\n",
    "    @abc.abstractmethod\n",
    "    def compute_value(self, integral_image):\n",
    "        '''\n",
    "        Функция, вычисляющая и возвращающая значение признака\n",
    "\n",
    "        На входе:\n",
    "            integral_image -- IntegralImage\n",
    "\n",
    "        На выходе:\n",
    "            Значение признака\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Feature {}, {}, {}, {}\".format(self.x, self.y, self.w, self.h)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Пример реализации признака (a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class HaarFeatureVerticalTwoSegments(HaarFeature):\n",
    "    def __init__(self, x, y, w, h):\n",
    "        assert (h % 2 == 0)\n",
    "        assert (x >= 0)\n",
    "        assert (y >= 0)\n",
    "        assert (w >= 2)\n",
    "        assert (h >= 2)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def compute_value(self, integral_image):\n",
    "        s1 = integral_image.sum(self.x, self.y, self.x + self.w - 1, self.y + self.h // 2 - 1)\n",
    "        s2 = integral_image.sum(self.x, self.y + self.h // 2, self.x + self.w - 1, self.y + self.h - 1)\n",
    "        return s1 - s2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "test_image = np.asarray([\n",
    "    [1, 1, 2, 2],\n",
    "    [1, 1, 2, 2],\n",
    "    [1, 1, 2, 2]\n",
    "])\n",
    "\n",
    "test_feature = HaarFeatureVerticalTwoSegments(0, 0, 3, 4)\n",
    "assert (test_feature.compute_value(IntegralImage(test_image)) == 6 * 1 - 6 * 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "По аналогии реализуйте остальные признаки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# признак (b)\n",
    "class HaarFeatureHorizontalTwoSegments(HaarFeature):\n",
    "\n",
    "    def __init__(self, x, y, w, h):\n",
    "        assert (w % 2 == 0)\n",
    "        assert (x >= 0)\n",
    "        assert (y >= 0)\n",
    "        assert (w >= 2)\n",
    "        assert (h >= 2)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def compute_value(self, integral_image):\n",
    "        s1 = integral_image.sum(self.x, self.y, self.x + self.w // 2 - 1, self.y + self.h - 1)\n",
    "        s2 = integral_image.sum(self.x + self.w // 2, self.y, self.x + self.w - 1, self.y + self.h - 1)\n",
    "        return s2 - s1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "test_image = np.asarray([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "    [2, 2, 2, 2],\n",
    "    [2, 2, 2, 2]\n",
    "])\n",
    "\n",
    "test_feature = HaarFeatureHorizontalTwoSegments(0, 0, 4, 4)\n",
    "assert (test_feature.compute_value(IntegralImage(test_image)) == 8 * 2 - 8 * 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# признак (c)\n",
    "class HaarFeatureVerticalThreeSegments(HaarFeature):\n",
    "\n",
    "    def __init__(self, x, y, w, h):\n",
    "        assert (h % 3 == 0)\n",
    "        assert (x >= 0)\n",
    "        assert (y >= 0)\n",
    "        assert (w >= 2)\n",
    "        assert (h >= 3)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def compute_value(self, integral_image):\n",
    "        s1 = integral_image.sum(self.x, self.y, self.x + self.w - 1, self.y + self.h - 1)\n",
    "        s2 = integral_image.sum(self.x, self.y + self.h // 3, self.x + self.w - 1, self.y + self.h // 3 * 2 - 1)\n",
    "        # print(s1, s2)\n",
    "        return s1 - 2 * s2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6 -6\n"
     ]
    }
   ],
   "source": [
    "test_image = np.asarray([\n",
    "    [1, 1, 3, 3, 1, 1],\n",
    "    [1, 1, 3, 3, 1, 1],\n",
    "    [1, 1, 3, 3, 1, 1]\n",
    "])\n",
    "\n",
    "test_feature = HaarFeatureVerticalThreeSegments(0, 0, 3, 6)\n",
    "print(test_feature.compute_value(IntegralImage(test_image)), 6 * 2 - 6 * 3)\n",
    "assert (test_feature.compute_value(IntegralImage(test_image)) == 6 * 2 - 6 * 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# признак (d)\n",
    "class HaarFeatureHorizontalThreeSegments(HaarFeature):\n",
    "    def __init__(self, x, y, w, h):\n",
    "        assert (w % 3 == 0)\n",
    "        assert (x >= 0)\n",
    "        assert (y >= 0)\n",
    "        assert (w >= 3)\n",
    "        assert (h >= 2)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def compute_value(self, integral_image):\n",
    "        s1 = integral_image.sum(self.x, self.y, self.x + self.w - 1, self.y + self.h - 1)\n",
    "        s2 = integral_image.sum(self.x + self.w // 3, self.y, self.x + self.w // 3 * 2 - 1, self.y + self.h - 1)\n",
    "        # print(s1, s2, self.x + self.w // 3, self.x + self.w // 3 * 2)\n",
    "        return s1 - 2 * s2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6 -6\n"
     ]
    }
   ],
   "source": [
    "test_image = np.asarray([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [3, 3, 3],\n",
    "    [3, 3, 3],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "\n",
    "test_feature = HaarFeatureHorizontalThreeSegments(0, 0, 6, 3)\n",
    "print(test_feature.compute_value(IntegralImage(test_image)), 6 * 2 - 6 * 3)\n",
    "assert (test_feature.compute_value(IntegralImage(test_image)) == 6 * 2 - 6 * 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# признак (e)\n",
    "class HaarFeatureFourSegments(HaarFeature):\n",
    "    def __init__(self, x, y, w, h):\n",
    "        assert (w % 2 == 0)\n",
    "        assert (h % 2 == 0)\n",
    "        assert (x >= 0)\n",
    "        assert (y >= 0)\n",
    "        assert (w >= 2)\n",
    "        assert (h >= 2)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def compute_value(self, integral_image):\n",
    "        s1 = integral_image.sum(self.x, self.y, self.x + self.w // 2 - 1, self.y + self.h // 2 - 1)\n",
    "        s1 += integral_image.sum(self.x + self.w // 2, self.y + self.h // 2, self.x + self.w - 1, self.y + self.h - 1)\n",
    "        s2 = integral_image.sum(self.x + self.w // 2, self.y, self.x + self.w - 1, self.y + self.h // 2 - 1)\n",
    "        s2 += integral_image.sum(self.x, self.y + self.h // 2, self.x + self.w // 2 - 1, self.y + self.h - 1)\n",
    "        # print(s1, s2)\n",
    "        return s1 - s2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "test_image = np.asarray([\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 1, 1],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 1, 1]\n",
    "])\n",
    "\n",
    "test_feature = HaarFeatureFourSegments(0, 0, 4, 4)\n",
    "print(test_feature.compute_value(IntegralImage(test_image)), 4 * 2 - 2)\n",
    "assert (test_feature.compute_value(IntegralImage(test_image)) == 4 * 2 - 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Сохраним все возможные признаки\n",
    "\n",
    "Теперь необходимо сгенерировать все возможные признаки. Для изображение 24 * 24 их получится очень много (около 150000). Чтобы сократить время вычислений, рекомендуется брать не все признаки, а некоторое подмножество. Например, можно рассматривать окна с некоторым шагом по x, y, т.к. соседние признаки все равно сильно скоррелированы. Также можно рассматривать окна не всех размеров, а тоже выбирать их с некоторым шагом. В зависимости вот возможностей компьютера, выберите шаги. 10-50 тысяч признаков должно хватить для классификатора разумной точности."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего признаков: 21684\n"
     ]
    }
   ],
   "source": [
    "features_to_use = [HaarFeatureVerticalTwoSegments,\n",
    "                   HaarFeatureVerticalThreeSegments,\n",
    "                   HaarFeatureHorizontalTwoSegments,\n",
    "                   HaarFeatureHorizontalThreeSegments,\n",
    "                   HaarFeatureFourSegments]\n",
    "# шаги по x,y,w,h\n",
    "x_stride = 2\n",
    "y_stride = 2\n",
    "w_stride = 2\n",
    "h_stride = 2\n",
    "\n",
    "all_features = []\n",
    "for x in range(0, image_canonical_size, x_stride):\n",
    "    for y in range(0, image_canonical_size, y_stride):\n",
    "        for w in range(2, image_canonical_size - x + 1, w_stride):\n",
    "            for h in range(2, image_canonical_size - y + 1, h_stride):\n",
    "                for feature_type in features_to_use:\n",
    "                    try:\n",
    "                        feature = feature_type(x, y, w, h)\n",
    "                        all_features.append(feature)\n",
    "                    except:\n",
    "                        continue\n",
    "print(f\"Всего признаков: {len(all_features)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Вычислим все признаки на всех изображениях"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def compute_features_for_image(integral_image, features):\n",
    "    result = np.zeros(len(features))\n",
    "    for ind, feature in enumerate(features):\n",
    "        result[ind] = feature.compute_value(integral_image)\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_features(integral_images, features):\n",
    "    result = np.zeros((len(integral_images), len(features)))\n",
    "    for ind, integral_image in tqdm(enumerate(integral_images)):\n",
    "        result[ind] = compute_features_for_image(integral_image, features)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75caa0c616c14ecaac67ed6d8cc23901"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b1d8bee494c4aa2bf6fd676d1162f72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_features = compute_features(integral_positives, all_features)\n",
    "negative_features = compute_features(integral_negatives, all_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Сохраним прогресс"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "positive = open('positive_data.pkl', 'wb')\n",
    "pickle.dump(positive_features, positive, 2)\n",
    "\n",
    "negative = open('negative_data.pkl', 'wb')\n",
    "pickle.dump(negative_features, negative, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
